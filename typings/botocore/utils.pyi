"""
This type stub file was generated by pyright.
"""

logger = ...
DEFAULT_METADATA_SERVICE_TIMEOUT = ...
METADATA_BASE_URL = ...
METADATA_BASE_URL_IPv6 = ...
METADATA_ENDPOINT_MODES = ...
SAFE_CHARS = ...
LABEL_RE = ...
RETRYABLE_HTTP_ERRORS = ...
S3_ACCELERATE_WHITELIST = ...
EVENT_ALIASES = ...
CHECKSUM_HEADER_PATTERN = ...
def ensure_boolean(val): # -> bool:
    """Ensures a boolean value if a string or boolean is provided

    For strings, the value for True/False is case insensitive
    """
    ...

def resolve_imds_endpoint_mode(session): # -> Literal['ipv4', 'ipv6']:
    """Resolving IMDS endpoint mode to either IPv6 or IPv4.

    ec2_metadata_service_endpoint_mode takes precedence over imds_use_ipv6.
    """
    ...

def is_json_value_header(shape): # -> Literal[False]:
    """Determines if the provided shape is the special header type jsonvalue.

    :type shape: botocore.shape
    :param shape: Shape to be inspected for the jsonvalue trait.

    :return: True if this type is a jsonvalue, False otherwise
    :rtype: Bool
    """
    ...

def has_header(header_name, headers): # -> bool:
    """Case-insensitive check for header key."""
    ...

def get_service_module_name(service_model): # -> str:
    """Returns the module name for a service

    This is the value used in both the documentation and client class name
    """
    ...

def normalize_url_path(path): # -> LiteralString | Literal['/', '']:
    ...

def normalize_boolean(val): # -> bool:
    """Returns None if val is None, otherwise ensure value
    converted to boolean"""
    ...

def remove_dot_segments(url): # -> LiteralString | Literal['']:
    ...

def validate_jmespath_for_set(expression): # -> None:
    ...

def set_value_from_jmespath(source, expression, value, is_first=...): # -> None:
    ...

def is_global_accesspoint(context):
    """Determine if request is intended for an MRAP accesspoint."""
    ...

class _RetriesExceededError(Exception):
    """Internal exception used when the number of retries are exceeded."""
    ...


class BadIMDSRequestError(Exception):
    def __init__(self, request) -> None:
        ...
    


class IMDSFetcher:
    _RETRIES_EXCEEDED_ERROR_CLS = _RetriesExceededError
    _TOKEN_PATH = ...
    _TOKEN_TTL = ...
    def __init__(self, timeout=..., num_attempts=..., base_url=..., env=..., user_agent=..., config=...) -> None:
        ...
    
    def get_base_url(self): # -> str:
        ...
    


class InstanceMetadataFetcher(IMDSFetcher):
    _URL_PATH = ...
    _REQUIRED_CREDENTIAL_FIELDS = ...
    def retrieve_iam_role_credentials(self): # -> dict[str, Any] | dict[Any, Any]:
        ...
    


class IMDSRegionProvider:
    def __init__(self, session, environ=..., fetcher=...) -> None:
        """Initialize IMDSRegionProvider.
        :type session: :class:`botocore.session.Session`
        :param session: The session is needed to look up configuration for
            how to contact the instance metadata service. Specifically the
            whether or not it should use the IMDS region at all, and if so how
            to configure the timeout and number of attempts to reach the
            service.
        :type environ: None or dict
        :param environ: A dictionary of environment variables to use. If
            ``None`` is the argument then ``os.environ`` will be used by
            default.
        :type fecther: :class:`botocore.utils.InstanceMetadataRegionFetcher`
        :param fetcher: The class to actually handle the fetching of the region
            from the IMDS. If not provided a default one will be created.
        """
        ...
    
    def provide(self): # -> None:
        """Provide the region value from IMDS."""
        ...
    


class InstanceMetadataRegionFetcher(IMDSFetcher):
    _URL_PATH = ...
    def retrieve_region(self): # -> None:
        """Get the current region from the instance metadata service.
        :rvalue: str
        :returns: The region the current instance is running in or None
            if the instance metadata service cannot be contacted or does not
            give a valid response.
        :rtype: None or str
        :returns: Returns the region as a string if it is configured to use
            IMDS as a region source. Otherwise returns ``None``. It will also
            return ``None`` if it fails to get the region from IMDS due to
            exhausting its retries or not being able to connect.
        """
        ...
    


def merge_dicts(dict1, dict2, append_lists=...): # -> None:
    """Given two dict, merge the second dict into the first.

    The dicts can have arbitrary nesting.

    :param append_lists: If true, instead of clobbering a list with the new
        value, append all of the new values onto the original list.
    """
    ...

def lowercase_dict(original): # -> dict[Any, Any]:
    """Copies the given dictionary ensuring all keys are lowercase strings."""
    ...

def parse_key_val_file(filename, _open=...): # -> dict[Any, Any]:
    ...

def parse_key_val_file_contents(contents): # -> dict[Any, Any]:
    ...

def percent_encode_sequence(mapping, safe=...): # -> LiteralString:
    """Urlencode a dict or list into a string.

    This is similar to urllib.urlencode except that:

    * It uses quote, and not quote_plus
    * It has a default list of safe chars that don't need
      to be encoded, which matches what AWS services expect.

    If any value in the input ``mapping`` is a list type,
    then each list element wil be serialized.  This is the equivalent
    to ``urlencode``'s ``doseq=True`` argument.

    This function should be preferred over the stdlib
    ``urlencode()`` function.

    :param mapping: Either a dict to urlencode or a list of
        ``(key, value)`` pairs.

    """
    ...

def percent_encode(input_str, safe=...): # -> str:
    """Urlencodes a string.

    Whereas percent_encode_sequence handles taking a dict/sequence and
    producing a percent encoded string, this function deals only with
    taking a string (not a dict/sequence) and percent encoding it.

    If given the binary type, will simply URL encode it. If given the
    text type, will produce the binary type by UTF-8 encoding the
    text. If given something else, will convert it to the text type
    first.
    """
    ...

def parse_timestamp(value): # -> datetime:
    """Parse a timestamp into a datetime object.

    Supported formats:

        * iso8601
        * rfc822
        * epoch (value is an integer)

    This will return a ``datetime.datetime`` object.

    """
    ...

def parse_to_aware_datetime(value): # -> datetime:
    """Converted the passed in value to a datetime object with tzinfo.

    This function can be used to normalize all timestamp inputs.  This
    function accepts a number of different types of inputs, but
    will always return a datetime.datetime object with time zone
    information.

    The input param ``value`` can be one of several types:

        * A datetime object (both naive and aware)
        * An integer representing the epoch time (can also be a string
          of the integer, i.e '0', instead of 0).  The epoch time is
          considered to be UTC.
        * An iso8601 formatted timestamp.  This does not need to be
          a complete timestamp, it can contain just the date portion
          without the time component.

    The returned value will be a datetime object that will have tzinfo.
    If no timezone info was provided in the input value, then UTC is
    assumed, not local time.

    """
    ...

def datetime2timestamp(dt, default_timezone=...):
    """Calculate the timestamp based on the given datetime instance.

    :type dt: datetime
    :param dt: A datetime object to be converted into timestamp
    :type default_timezone: tzinfo
    :param default_timezone: If it is provided as None, we treat it as tzutc().
                             But it is only used when dt is a naive datetime.
    :returns: The timestamp
    """
    ...

def calculate_sha256(body, as_hex=...): # -> str | bytes:
    """Calculate a sha256 checksum.

    This method will calculate the sha256 checksum of a file like
    object.  Note that this method will iterate through the entire
    file contents.  The caller is responsible for ensuring the proper
    starting position of the file and ``seek()``'ing the file back
    to its starting location if other consumers need to read from
    the file like object.

    :param body: Any file like object.  The file must be opened
        in binary mode such that a ``.read()`` call returns bytes.
    :param as_hex: If True, then the hex digest is returned.
        If False, then the digest (as binary bytes) is returned.

    :returns: The sha256 checksum

    """
    ...

def calculate_tree_hash(body): # -> str:
    """Calculate a tree hash checksum.

    For more information see:

    http://docs.aws.amazon.com/amazonglacier/latest/dev/checksum-calculations.html

    :param body: Any file like object.  This has the same constraints as
        the ``body`` param in calculate_sha256

    :rtype: str
    :returns: The hex version of the calculated tree hash

    """
    ...

class CachedProperty:
    """A read only property that caches the initially computed value.

    This descriptor will only call the provided ``fget`` function once.
    Subsequent access to this property will return the cached value.

    """
    def __init__(self, fget) -> None:
        ...
    
    def __get__(self, obj, cls): # -> Self:
        ...
    


class ArgumentGenerator:
    """Generate sample input based on a shape model.

    This class contains a ``generate_skeleton`` method that will take
    an input/output shape (created from ``botocore.model``) and generate
    a sample dictionary corresponding to the input/output shape.

    The specific values used are place holder values. For strings either an
    empty string or the member name can be used, for numbers 0 or 0.0 is used.
    The intended usage of this class is to generate the *shape* of the input
    structure.

    This can be useful for operations that have complex input shapes.
    This allows a user to just fill in the necessary data instead of
    worrying about the specific structure of the input arguments.

    Example usage::

        s = botocore.session.get_session()
        ddb = s.get_service_model('dynamodb')
        arg_gen = ArgumentGenerator()
        sample_input = arg_gen.generate_skeleton(
            ddb.operation_model('CreateTable').input_shape)
        print("Sample input for dynamodb.CreateTable: %s" % sample_input)

    """
    def __init__(self, use_member_names=...) -> None:
        ...
    
    def generate_skeleton(self, shape): # -> dict[Any, Any] | OrderedDict[Any, Any] | list[dict[Any, Any] | OrderedDict[Any, Any] | OrderedDict[Literal['KeyName'], dict[Any, Any] | OrderedDict[Any, Any] | str | Any | float | datetime | Literal[0, True] | None] | str | Any | float | datetime | int | bool | None] | OrderedDict[Literal['KeyName'], dict[Any, Any] | OrderedDict[Any, Any] | str | Any | float | datetime | Literal[0, True] | None] | str | float | datetime | Literal[0, True] | None:
        """Generate a sample input.

        :type shape: ``botocore.model.Shape``
        :param shape: The input shape.

        :return: The generated skeleton input corresponding to the
            provided input shape.

        """
        ...
    


def is_valid_ipv6_endpoint_url(endpoint_url): # -> bool:
    ...

def is_valid_ipv4_endpoint_url(endpoint_url): # -> bool:
    ...

def is_valid_endpoint_url(endpoint_url): # -> Match[str] | Literal[False] | None:
    """Verify the endpoint_url is valid.

    :type endpoint_url: string
    :param endpoint_url: An endpoint_url.  Must have at least a scheme
        and a hostname.

    :return: True if the endpoint url is valid. False otherwise.

    """
    ...

def is_valid_uri(endpoint_url): # -> Match[str] | bool:
    ...

def validate_region_name(region_name): # -> None:
    """Provided region_name must be a valid host label."""
    ...

def check_dns_name(bucket_name): # -> bool:
    """
    Check to see if the ``bucket_name`` complies with the
    restricted DNS naming conventions necessary to allow
    access via virtual-hosting style.

    Even though "." characters are perfectly valid in this DNS
    naming scheme, we are going to punt on any name containing a
    "." character because these will cause SSL cert validation
    problems if we try to use virtual-hosting style addressing.
    """
    ...

def fix_s3_host(request, signature_version, region_name, default_endpoint_url=..., **kwargs): # -> None:
    """
    This handler looks at S3 requests just before they are signed.
    If there is a bucket name on the path (true for everything except
    ListAllBuckets) it checks to see if that bucket name conforms to
    the DNS naming conventions.  If it does, it alters the request to
    use ``virtual hosting`` style addressing rather than ``path-style``
    addressing.

    """
    ...

def switch_to_virtual_host_style(request, signature_version, default_endpoint_url=..., **kwargs): # -> None:
    """
    This is a handler to force virtual host style s3 addressing no matter
    the signature version (which is taken in consideration for the default
    case). If the bucket is not DNS compatible an InvalidDNSName is thrown.

    :param request: A AWSRequest object that is about to be sent.
    :param signature_version: The signature version to sign with
    :param default_endpoint_url: The endpoint to use when switching to a
        virtual style. If None is supplied, the virtual host will be
        constructed from the url of the request.
    """
    ...

def instance_cache(func): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """Method decorator for caching method calls to a single instance.

    **This is not a general purpose caching decorator.**

    In order to use this, you *must* provide an ``_instance_cache``
    attribute on the instance.

    This decorator is used to cache method calls.  The cache is only
    scoped to a single instance though such that multiple instances
    will maintain their own cache.  In order to keep things simple,
    this decorator requires that you provide an ``_instance_cache``
    attribute on your instance.

    """
    ...

def lru_cache_weakref(*cache_args, **cache_kwargs): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    """
    Version of functools.lru_cache that stores a weak reference to ``self``.

    Serves the same purpose as :py:func:`instance_cache` but uses Python's
    functools implementation which offers ``max_size`` and ``typed`` properties.

    lru_cache is a global cache even when used on a method. The cache's
    reference to ``self`` will prevent garbace collection of the object. This
    wrapper around functools.lru_cache replaces the reference to ``self`` with
    a weak reference to not interfere with garbage collection.
    """
    ...

def switch_host_s3_accelerate(request, operation_name, **kwargs): # -> None:
    """Switches the current s3 endpoint with an S3 Accelerate endpoint"""
    ...

def switch_host_with_param(request, param_name): # -> None:
    """Switches the host using a parameter value from a JSON request body"""
    ...

def deep_merge(base, extra): # -> None:
    """Deeply two dictionaries, overriding existing keys in the base.

    :param base: The base dictionary which will be merged into.
    :param extra: The dictionary to merge into the base. Keys from this
        dictionary will take precedence.
    """
    ...

def hyphenize_service_id(service_id):
    """Translate the form used for event emitters.

    :param service_id: The service_id to convert.
    """
    ...

class S3RegionRedirectorv2:
    """Updated version of S3RegionRedirector for use when
    EndpointRulesetResolver is in use for endpoint resolution.

    This class is considered private and subject to abrupt breaking changes or
    removal without prior announcement. Please do not use it directly.
    """
    def __init__(self, endpoint_bridge, client, cache=...) -> None:
        ...
    
    def register(self, event_emitter=...): # -> None:
        ...
    
    def redirect_from_error(self, request_dict, response, operation, **kwargs): # -> Literal[0] | None:
        """
        An S3 request sent to the wrong region will return an error that
        contains the endpoint the request should be sent to. This handler
        will add the redirect information to the signing context and then
        redirect the request.
        """
        ...
    
    def get_bucket_region(self, bucket, response): # -> Any:
        """
        There are multiple potential sources for the new region to redirect to,
        but they aren't all universally available for use. This will try to
        find region from response elements, but will fall back to calling
        HEAD on the bucket if all else fails.

        :param bucket: The bucket to find the region for. This is necessary if
            the region is not available in the error response.
        :param response: A response representing a service request that failed
            due to incorrect region configuration.
        """
        ...
    
    def set_request_url(self, old_url, new_endpoint, **kwargs): # -> str:
        """
        Splice a new endpoint into an existing URL. Note that some endpoints
        from the the endpoint provider have a path component which will be
        discarded by this function.
        """
        ...
    
    def redirect_from_cache(self, builtins, params, **kwargs): # -> None:
        """
        If a bucket name has been redirected before, it is in the cache. This
        handler will update the AWS::Region endpoint resolver builtin param
        to use the region from cache instead of the client region to avoid the
        redirect.
        """
        ...
    
    def annotate_request_context(self, params, context, **kwargs): # -> None:
        """Store the bucket name in context for later use when redirecting.
        The bucket name may be an access point ARN or alias.
        """
        ...
    


class S3RegionRedirector:
    """This handler has been replaced by S3RegionRedirectorv2. The original
    version remains in place for any third-party libraries that import it.
    """
    def __init__(self, endpoint_bridge, client, cache=...) -> None:
        ...
    
    def register(self, event_emitter=...): # -> None:
        ...
    
    def redirect_from_error(self, request_dict, response, operation, **kwargs): # -> Literal[0] | None:
        """
        An S3 request sent to the wrong region will return an error that
        contains the endpoint the request should be sent to. This handler
        will add the redirect information to the signing context and then
        redirect the request.
        """
        ...
    
    def get_bucket_region(self, bucket, response): # -> Any:
        """
        There are multiple potential sources for the new region to redirect to,
        but they aren't all universally available for use. This will try to
        find region from response elements, but will fall back to calling
        HEAD on the bucket if all else fails.

        :param bucket: The bucket to find the region for. This is necessary if
            the region is not available in the error response.
        :param response: A response representing a service request that failed
            due to incorrect region configuration.
        """
        ...
    
    def set_request_url(self, params, context, **kwargs): # -> None:
        ...
    
    def redirect_from_cache(self, params, context, **kwargs): # -> None:
        """
        This handler retrieves a given bucket's signing context from the cache
        and adds it into the request context.
        """
        ...
    


class InvalidArnException(ValueError):
    ...


class ArnParser:
    def parse_arn(self, arn): # -> dict[str, Any]:
        ...
    
    @staticmethod
    def is_arn(value): # -> bool:
        ...
    


class S3ArnParamHandler:
    _RESOURCE_REGEX = ...
    _OUTPOST_RESOURCE_REGEX = ...
    _BLACKLISTED_OPERATIONS = ...
    def __init__(self, arn_parser=...) -> None:
        ...
    
    def register(self, event_emitter): # -> None:
        ...
    
    def handle_arn(self, params, model, context, **kwargs): # -> None:
        ...
    


class S3EndpointSetter:
    _DEFAULT_PARTITION = ...
    _DEFAULT_DNS_SUFFIX = ...
    def __init__(self, endpoint_resolver, region=..., s3_config=..., endpoint_url=..., partition=..., use_fips_endpoint=...) -> None:
        ...
    
    def register(self, event_emitter): # -> None:
        ...
    
    def update_endpoint_to_s3_object_lambda(self, params, context, **kwargs): # -> None:
        ...
    
    def set_endpoint(self, request, **kwargs): # -> None:
        ...
    
    def set_signer(self, context, **kwargs): # -> Literal['s3v4a'] | None:
        ...
    


class S3ControlEndpointSetter:
    _DEFAULT_PARTITION = ...
    _DEFAULT_DNS_SUFFIX = ...
    _HOST_LABEL_REGEX = ...
    def __init__(self, endpoint_resolver, region=..., s3_config=..., endpoint_url=..., partition=..., use_fips_endpoint=...) -> None:
        ...
    
    def register(self, event_emitter): # -> None:
        ...
    
    def set_endpoint(self, request, **kwargs): # -> None:
        ...
    


class S3ControlArnParamHandler:
    """This handler has been replaced by S3ControlArnParamHandlerv2. The
    original version remains in place for any third-party importers.
    """
    _RESOURCE_SPLIT_REGEX = ...
    def __init__(self, arn_parser=...) -> None:
        ...
    
    def register(self, event_emitter): # -> None:
        ...
    
    def handle_arn(self, params, model, context, **kwargs): # -> None:
        ...
    


class S3ControlArnParamHandlerv2(S3ControlArnParamHandler):
    """Updated version of S3ControlArnParamHandler for use when
    EndpointRulesetResolver is in use for endpoint resolution.

    This class is considered private and subject to abrupt breaking changes or
    removal without prior announcement. Please do not use it directly.
    """
    def __init__(self, arn_parser=...) -> None:
        ...
    
    def register(self, event_emitter): # -> None:
        ...
    


class ContainerMetadataFetcher:
    TIMEOUT_SECONDS = ...
    RETRY_ATTEMPTS = ...
    SLEEP_TIME = ...
    IP_ADDRESS = ...
    _ALLOWED_HOSTS = ...
    def __init__(self, session=..., sleep=...) -> None:
        ...
    
    def retrieve_full_uri(self, full_url, headers=...): # -> Any:
        """Retrieve JSON metadata from container metadata.

        :type full_url: str
        :param full_url: The full URL of the metadata service.
            This should include the scheme as well, e.g
            "http://localhost:123/foo"

        """
        ...
    
    def retrieve_uri(self, relative_uri): # -> Any:
        """Retrieve JSON metadata from container metadata.

        :type relative_uri: str
        :param relative_uri: A relative URI, e.g "/foo/bar?id=123"

        :return: The parsed JSON response.

        """
        ...
    
    def full_url(self, relative_uri): # -> str:
        ...
    


def get_environ_proxies(url): # -> dict[Any, Any] | dict[str, str]:
    ...

def should_bypass_proxies(url): # -> bool:
    """
    Returns whether we should bypass proxies or not.
    """
    ...

def determine_content_length(body): # -> int | None:
    ...

def get_encoding_from_headers(headers, default=...): # -> _ParamType | None:
    """Returns encodings from given HTTP Header Dict.

    :param headers: dictionary to extract encoding from.
    :param default: default encoding if the content-type is text
    """
    ...

def calculate_md5(body, **kwargs): # -> str:
    ...

def conditionally_calculate_md5(params, **kwargs): # -> None:
    """Only add a Content-MD5 if the system supports it."""
    ...

class FileWebIdentityTokenLoader:
    def __init__(self, web_identity_token_path, _open=...) -> None:
        ...
    
    def __call__(self):
        ...
    


class SSOTokenLoader:
    def __init__(self, cache=...) -> None:
        ...
    
    def save_token(self, start_url, token, session_name=...): # -> None:
        ...
    
    def __call__(self, start_url, session_name=...):
        ...
    


class EventbridgeSignerSetter:
    _DEFAULT_PARTITION = ...
    _DEFAULT_DNS_SUFFIX = ...
    def __init__(self, endpoint_resolver, region=..., endpoint_url=...) -> None:
        ...
    
    def register(self, event_emitter): # -> None:
        ...
    
    def set_endpoint_url(self, params, context, **kwargs): # -> None:
        ...
    
    def check_for_global_endpoint(self, params, context, **kwargs): # -> None:
        ...
    


def is_s3_accelerate_url(url): # -> bool:
    """Does the URL match the S3 Accelerate endpoint scheme?

    Virtual host naming style with bucket names in the netloc part of the URL
    are not allowed by this function.
    """
    ...

class JSONFileCache:
    """JSON file cache.
    This provides a dict like interface that stores JSON serializable
    objects.
    The objects are serialized to JSON and stored in a file.  These
    values can be retrieved at a later time.
    """
    CACHE_DIR = ...
    def __init__(self, working_dir=..., dumps_func=...) -> None:
        ...
    
    def __contains__(self, cache_key): # -> bool:
        ...
    
    def __getitem__(self, cache_key): # -> Any:
        """Retrieve value from a cache key."""
        ...
    
    def __delitem__(self, cache_key): # -> None:
        ...
    
    def __setitem__(self, cache_key, value): # -> None:
        ...
    


SERVICE_NAME_ALIASES = ...
CLIENT_NAME_TO_HYPHENIZED_SERVICE_ID_OVERRIDES = ...
